{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:2.4.2`\n",
    "import $ivy.`co.datamechanics:delight_2.12:latest-SNAPSHOT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coursierapi.Credentials\n",
    "import coursierapi.MavenRepository\n",
    "\n",
    "interp.repositories() ++= Seq(\n",
    "    MavenRepository.of(\"https://oss.sonatype.org/content/repositories/snapshots\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val spark = SparkSession\n",
    "  .builder()\n",
    "  .appName(\"Spark SQL basic example\")\n",
    "  .config(\"spark.master\", \"local\")\n",
    "  .config(\"spark.delight.accessToken.secret\",\"\")\n",
    "  .config(\"spark.extraListeners\",\"co.datamechanics.delight.DelightListener\")\n",
    ".getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spark.implicits._\n",
    "\n",
    "val dataset = Seq((0, \"hello\"), (1, \"world\")).toDF(\"id\", \"text\")\n",
    "val upper: String => String = _.toUpperCase\n",
    "\n",
    "// Define a UDF that wraps the upper Scala function defined above\n",
    "// You could also define the function in place, i.e. inside udf\n",
    "// but separating Scala functions from Spark SQL's UDFs allows for easier testing\n",
    "import org.apache.spark.sql.functions.udf\n",
    "val upperUDF = udf(upper)\n",
    "\n",
    "// Apply the UDF to change the source dataset\n",
    "dataset.withColumn(\"upper\", upperUDF('text)).show"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "plaintext"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
